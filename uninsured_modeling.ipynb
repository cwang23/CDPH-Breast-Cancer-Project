{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Uninsured Population (2017)\n",
    "This notebook goes through the steps of creating a model to predict the uninsured population in America in 2017.\n",
    "\n",
    "First, we'll set up our workspace. We'll be using the Civis Analytics platform API to connect to our data, create tables, and query our data. Through the Civis API, we'll also be able to use CivisML, our machine learning package. We'll use this to train and test our models, as well as make predictions.\n",
    "\n",
    "To learn more about Civis Analytics and understand the data science platform we use to build this model, check out our website at the following link: https://www.civisanalytics.com/\n",
    "\n",
    "#### NOTE: Some variable names and functions have been changed to protect proprietary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "import imp\n",
    "import civis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from civis.ml import ModelPipeline  # we'll be using Civis's model pipeline to create and run our models\n",
    "\n",
    "client = civis.APIClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Create Training Table\n",
    "\n",
    "1.  Grab data for modeling\n",
    "2.  Append on 2016 uninsured scores\n",
    "3.  Append responses from the survey we ran in 2017 (Oct 23, 2017 - Nov 24, 2017)\n",
    "4.  Recode survey question about insurance status to be binary variable where uninsured = 1, insured = 0\n",
    "5.  Rebalance table so that the split is approximately 80/20 for insured/uninsured, as there are too many insured people in the dataset to properly train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery redshift-general  -- this allows us to query our data using SQL in this cell\n",
    "\n",
    "\n",
    "SET SEED TO .42;\n",
    "\n",
    "DROP VIEW IF EXISTS cdph_train_uninsured;\n",
    "CREATE VIEW cdph_train_uninsured AS\n",
    "(\n",
    "SELECT *\n",
    "FROM\n",
    "(\n",
    "    SELECT full_modeling_data.*, \n",
    "    s.cdph_uninsured\n",
    "    FROM\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM\n",
    "        (\n",
    "            SELECT \n",
    "            id,\n",
    "            DECODE(cdph_insured,\n",
    "                   'Yes - through the government (Medicare, Medicaid)', 0,\n",
    "                   'Yes - through my employer or spouse/partner\\'s employer, or I purchase it myself', 0,\n",
    "                   'No - I don\\'t have health insurance', 1,\n",
    "                   NULL) AS cdph_uninsured,\n",
    "            ROW_NUMBER() OVER (PARTITION BY id) AS dupes -- remove duplicate survey respondents\n",
    "            FROM health_care.cdph_survey\n",
    "       ) WHERE dupes = 1\n",
    "    ) AS s \n",
    "    LEFT JOIN\n",
    "    (\n",
    "      SELECT *\n",
    "      FROM modeling_data AS md\n",
    "      LEFT JOIN\n",
    "      (\n",
    "          SELECT join_key, uninsured_2016\n",
    "          FROM uninsured2016_data\n",
    "      ) AS 2016data\n",
    "      ON md.id = 2016data.join_key\n",
    "    ) AS full_modeling_data\n",
    "    ON full_modeling_data.id = s.id\n",
    ")\n",
    "WHERE cdph_uninsured = 1\n",
    ")\n",
    "UNION ALL\n",
    "(\n",
    "SELECT *\n",
    "FROM\n",
    "(\n",
    "    SELECT full_modeling_data.*, \n",
    "    s.cdph_uninsured\n",
    "    FROM\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM\n",
    "        (\n",
    "            SELECT \n",
    "            id,\n",
    "            DECODE(cdph_insured,\n",
    "                   'Yes - through the government (Medicare, Medicaid)', 0,\n",
    "                   'Yes - through my employer or spouse/partner\\'s employer, or I purchase it myself', 0,\n",
    "                   'No - I don\\'t have health insurance', 1,\n",
    "                   NULL) AS cdph_uninsured,\n",
    "            ROW_NUMBER() OVER (PARTITION BY id) AS dupes -- remove duplicate survey respondents\n",
    "            FROM health_care.cdph_survey\n",
    "       ) WHERE dupes = 1\n",
    "    ) AS s \n",
    "    LEFT JOIN\n",
    "    (\n",
    "      SELECT *\n",
    "      FROM modeling_data AS md\n",
    "      LEFT JOIN\n",
    "      (\n",
    "          SELECT join_key, uninsured_2016\n",
    "          FROM uninsured2016_data\n",
    "      ) AS 2016data\n",
    "      ON md.id = 2016data.join_key\n",
    "    ) AS full_modeling_data\n",
    "    ON full_modeling_data.id = s.id\n",
    ")\n",
    "WHERE cdph_uninsured = 0\n",
    "ORDER BY RANDOM()  -- take a random subset of insured people\n",
    "LIMIT 1940\n",
    ")\n",
    ";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Train Model\n",
    "To train our model, we'll first specify a few classifier models offered in the modeling package Civis uses, CivisML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'sparse_logistic': {},\n",
    "    'extra_trees_classifier': {\"hyperband\"},\n",
    "    'gradient_boosting_classifier': {\"hyperband\"},\n",
    "    'random_forest_classifier': {\"hyperband\"},\n",
    "    'extra_trees_classifier': {\"hyperband\"},\n",
    "    'multilayer_perceptron_classifier': {'hyperband'},\n",
    "    'stacking_classifier': {}\n",
    "} \n",
    "\n",
    "futures = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll loop through each of the models we specified. As of December 2017, we are using CivisML 2.0, which includes new models and more sophisticated tuning (i.e. \"hyperband\").\n",
    "\n",
    "For each model, we'll create a model pipeline where we provide the dependent variable and a primary key (i.e. a column with a unique indicator for each row or observation). We can also choose to exclude specific columns. We will then train the model using the training table we created.\n",
    "\n",
    "The CivisML modeling pipeline will automatically split the data into a train and test set, as well as cross-validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, params in models.items():\n",
    "    \n",
    "    # DEFAULT TO HYPERBAND WITH CivisML 2.0\n",
    "    if i == \"sparse_logistic\" or i == \"stacking_classifier\":\n",
    "        pass\n",
    "    else:\n",
    "        params = \"hyperband\"\n",
    "        \n",
    "    print(\"Currently testing model: \" + i)\n",
    "    print(\"Params: \" + str(params))\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "    m = ModelPipeline(model = i, \n",
    "                      model_name = 'Uninsured model ' + i + ' DV is: cdph_uninsured',\n",
    "                      dependent_variable = 'cdph_uninsured',\n",
    "                      primary_key = 'id',\n",
    "                      excluded_columns = ['state', \n",
    "                                          'join_key',\n",
    "                                          'cdph_pregnant',\n",
    "                                          'cdph_pregnant_age',\n",
    "                                          'cdph_diagnosis_breastcancer',\n",
    "                                          'cdph_family_breastcancer',\n",
    "                                          'cdph_brca_test',\n",
    "                                          'cdph_oral_contraceptives',\n",
    "                                          'cdph_female_hormones',\n",
    "                                         ],\n",
    "                      cross_validation_parameters = params,\n",
    "                      memory_requested = 3000,\n",
    "                      cpu_requested = 800)\n",
    "\n",
    "    train = m.train(table_name = 'cdph_train_uninsured',\n",
    "                    database_name = 'database')\n",
    "    futures.append(train)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if the models are running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in futures:\n",
    "    print(\"Model running?  \" + str(f.running()))\n",
    "    print(\"Job ID: \" + str(f.job_id))\n",
    "    print(\"Train Job ID: \" + str(f.train_job_id))\n",
    "    print(\"Run ID: \" + str(f.train_run_id))\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Compare Model Performance\n",
    "After our models have finished running, we'll print out the cross validation metrics for each one and compare them. We'll select the best performing model to score our dataset. \n",
    "\n",
    "#### The sparse logistic model ended up having the best performance among the 7 models we tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in futures: \n",
    "    print(\"\\n************************************\\n\")\n",
    "    if str(f.running()) == \"False\" and f.metadata['run']['status'] != \"exception\":\n",
    "        print(\"MODEL: \" + f.metadata['model']['model'])\n",
    "        print(\"DV: \" + f.metadata['run']['configuration']['data']['y'][0])\n",
    "        print(\"TRAINING TABLE: \" + f.metadata['data_platform']['table_source']['tablename'])\n",
    "        try:\n",
    "            print(\"\\n-----------------------\\n\")\n",
    "            print(\"AUC: \" + str(f.metrics['roc_auc']))\n",
    "            print(\"\\n------------------------\\n\")\n",
    "            print(\"CONFUSION MATRIX:  \" + str(f.metrics['confusion_matrix']))\n",
    "            print(\"\\n------------------------------------\\n\")\n",
    "            print(\"BEST PARAMS:\")\n",
    "            print(f.metadata['model']['cv_best_params'])\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\\n************************************\\n\")\n",
    "    else:\n",
    "        print(\"Model not finished running\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Create Scoring Table and Score\n",
    "We'll create a scoring table with the same features as our training set. This scoring table has data on Chicago inhabitants, so once we're done scoring, we can use this table to create a heat map illustrating where the uninsured population in Chicago resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery redshift-general\n",
    "\n",
    "DROP VIEW IF EXISTS score_table_uninsured2017;\n",
    "CREATE VIEW score_table_uninsured2017 AS\n",
    "SELECT A.*, B.score AS uninsured_2016\n",
    "FROM\n",
    "(\n",
    "  (\n",
    "    SELECT *\n",
    "    FROM modeling_data\n",
    "  ) AS A\n",
    "  LEFT JOIN\n",
    "  (\n",
    "    SELECT score, join_key\n",
    "    FROM 2016scores\n",
    "  ) AS B\n",
    "  ON A.id = B.join_key\n",
    ")\n",
    "WHERE B.score IS NOT NULL;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Civis API, we'll grab the model with the best performance (sparse logistic), and use this model to score our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Job ID, Run ID, name from output or Civis Platform UI\n",
    "job_id = ########\n",
    "run_id = client.jobs.get(job_id)['last_run']['id']\n",
    "name = client.jobs.get(job_id)['name']\n",
    "\n",
    "# Print Model Info\n",
    "print(\"NAME: \" + name)\n",
    "print(\"JOB ID: \" + str(job_id))\n",
    "print(\"RUN ID: \" + str(run_id))\n",
    "\n",
    "# Load model\n",
    "loaded_model = ModelPipeline.from_existing(job_id, run_id)\n",
    "\n",
    "model_type = loaded_model.model\n",
    "print(model_type)  # model type is sparse logistic\n",
    "\n",
    "# Score table using model\n",
    "scoring = loaded_model.predict(table_name = \"score_table_uninsured2017\", \n",
    "                        database_name = \"database\",\n",
    "                        output_table = \"uninsured2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Create Table for Plotting Map\n",
    "We'll grab the output scores and join them to a table with geographic information, which we will then use to create maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery redshift-general\n",
    "\n",
    "DROP TABLE IF EXISTS insurance_mapping;\n",
    "CREATE TABLE insurance_mapping \n",
    "AS\n",
    "SELECT \n",
    "insured_scores.uninsured2017, \n",
    "CASE WHEN insured_scores.uninsured2017 >= 0.5 THEN 1 ELSE 0 END AS uninsured2017_2cat,\n",
    "ds.* FROM\n",
    "(\n",
    "    (\n",
    "        SELECT id, cdph_uninsured_1 AS uninsured2017\n",
    "        FROM health_care.uninsured2017\n",
    "    ) AS insured_scores\n",
    "    LEFT JOIN\n",
    "    (\n",
    "        SELECT id, state, census_block, county, county_name\n",
    "        FROM dataset\n",
    "        WHERE gender = 'Female'\n",
    "    ) AS ds\n",
    "    ON insured_scores.id = ds.id\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
