{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1:  Uninsured Women in Chicago (2017)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "This notebook goes through the steps of creating a model to predict the population of uninsured Chicago women in 2017. We follow a 2-step modeling process to estimate the percentage of women in each Census tract in Chicago that are likely to be uninsured. In the first step, we'll train a model on individual-level data, where each row is a person. In the second step, we'll train a model on geographic-level data, where we use the same features as the individual-level model, but the values are aggregated by our geographic-level of interest (in this case, Census tracts). We'll then use our model to predict the proportion of uninsured women in each Census tract in Chicago.\n",
    "\n",
    "This 2-step modeling process helps us avoid a reverse ecological fallacy problem, or an exception fallacy, which is a potential problem that arises from modeling based off survey response data.\n",
    "\n",
    "To conduct our analyses, we'll be using the Civis Analytics platform API to connect to our data, create tables, and query our data. Through the Civis API, we'll also be able to use CivisML, our machine learning package. We'll use this to train and test our models, as well as make predictions.\n",
    "\n",
    "To learn more about Civis Analytics and understand the data science platform we use to build this model, check out our website at the following link: https://www.civisanalytics.com/\n",
    "\n",
    "#### NOTE: Some variable names and functions have been changed to protect proprietary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import civis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from civis.ml import ModelPipeline  # we'll be using Civis's model pipeline to create and run our models\n",
    "\n",
    "client = civis.APIClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 1: Create Individual-Level Training Table (female-only)\n",
    "\n",
    "1.  Grab data for modeling\n",
    "2.  Append on 2016 uninsured scores \n",
    "3.  Append responses from the survey we ran in 2017 (Oct - Nov 2017) -- only has data for women\n",
    "4.  Recode survey question about insurance status to be binary variable where uninsured = 1, insured = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery -- this allows us to query our data using SQL in this cell\n",
    "\n",
    "\n",
    "SET SEED TO .42;\n",
    "\n",
    "DROP VIEW IF EXISTS cdph_train_uninsured;\n",
    "CREATE VIEW cdph_train_uninsured AS\n",
    "SELECT *\n",
    "FROM\n",
    "(\n",
    "    SELECT full_modeling_data.*, \n",
    "    s.cdph_uninsured,\n",
    "    s.weight\n",
    "    FROM\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM\n",
    "        (\n",
    "            SELECT \n",
    "            id,\n",
    "            weight,\n",
    "            DECODE(cdph_insured,\n",
    "                   'Yes - through the government (Medicare, Medicaid)', 0,\n",
    "                   'Yes - through my employer or spouse/partner\\'s employer, or I purchase it myself', 0,\n",
    "                   'No - I don\\'t have health insurance', 1,\n",
    "                   NULL) AS cdph_uninsured,\n",
    "            ROW_NUMBER() OVER (PARTITION BY id) AS dupes -- remove duplicate survey respondents\n",
    "            FROM cdph_survey\n",
    "       ) WHERE dupes = 1\n",
    "    ) AS s \n",
    "    LEFT JOIN\n",
    "    (\n",
    "      SELECT *\n",
    "      FROM modeling_data AS md\n",
    "      LEFT JOIN\n",
    "      (\n",
    "          SELECT join_key, uninsured_2016\n",
    "          FROM uninsured2016_data\n",
    "      ) AS 2016data\n",
    "      ON md.id = 2016data.join_key\n",
    "    ) AS full_modeling_data\n",
    "    ON full_modeling_data.id = s.id\n",
    ")\n",
    "WHERE cdph_uninsured IS NOT NULL\n",
    ";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the training table, we'll check the distribution of the target variable (cdph_uninsured) to ensure that the target event is not too rare.\n",
    "\n",
    "We see that while few people are uninsured, the event is not too rare to the point where we have to rebalance the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"select count(cdph_uninsured) from cdph_train_uninsured\",\n",
    "        \"select count(cdph_uninsured) from cdph_train_uninsured where cdph_uninsured = 0\",\n",
    "        \"select count(cdph_uninsured) from cdph_train_uninsured where cdph_uninsured = 1\"\n",
    "        ]\n",
    "\n",
    "print(\"\\n------------------ CHECKING TARGET VARIABLE COUNTS ------------------\")\n",
    "for query in queries:\n",
    "    sql_q = query\n",
    "    print(sql_q)\n",
    "    q = client.queries.post(database=\"database_number\",\n",
    "                            sql= sql_q,\n",
    "                            preview_rows=100\n",
    "                           )\n",
    "    \n",
    "    while client.queries.get(q['id'])['state'] != \"succeeded\":\n",
    "        pass\n",
    "    print(client.queries.get(q['id'])['result_rows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 2: Train Individual-level Model\n",
    "To train our model, we'll first specify a few classifier models offered in the modeling package Civis uses, CivisML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'sparse_logistic': {},\n",
    "    'extra_trees_classifier': \"hyperband\",\n",
    "    'gradient_boosting_classifier': \"hyperband\",\n",
    "    'random_forest_classifier': \"hyperband\"\n",
    "} \n",
    "\n",
    "futures = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll loop through each of the models we specified. CivisML allows us to tune the hyperparameters of our models using \"hyperband\", which is a more efficient approach to hyperparameter optimization.\n",
    "\n",
    "For each model, we'll create a pipeline where we provide the dependent variable and a primary key (i.e. a column with a unique indicator for each row or observation). We can also choose to exclude specific columns. We will then train the model using the training table we created.\n",
    "\n",
    "The CivisML modeling pipeline automatically uses stratified k-fold cross validation to cross validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, params in models.items():\n",
    "        \n",
    "    print(\"Currently testing model: \" + i)\n",
    "    print(\"Params: \" + str(params))\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "    m = ModelPipeline(model = i, \n",
    "                      model_name = 'Uninsured Model ' + i + ' DV is: cdph_uninsured',\n",
    "                      dependent_variable = 'cdph_uninsured',\n",
    "                      primary_key = 'id',\n",
    "                      excluded_columns = ['state', \n",
    "                                          'join_key',\n",
    "                                          'cdph_pregnant',\n",
    "                                          'cdph_pregnant_age',\n",
    "                                          'cdph_diagnosis_breastcancer',\n",
    "                                          'cdph_family_breastcancer',\n",
    "                                          'cdph_brca_test',\n",
    "                                          'cdph_oral_contraceptives',\n",
    "                                          'cdph_female_hormones',\n",
    "                                         ],\n",
    "                      cross_validation_parameters = params,\n",
    "                      memory_requested = 3000,\n",
    "                      cpu_requested = 800)\n",
    "\n",
    "    train = m.train(table_name = 'cdph_train_uninsured',\n",
    "                    fit_params = {'sample_weight': 'weight'},\n",
    "                    database_name = 'database')\n",
    "    futures.append(train)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if the models are running in the Civis Platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in futures:\n",
    "    print(\"Model running?  \" + str(f.running()))\n",
    "    print(\"Job ID: \" + str(f.job_id))\n",
    "    print(\"Train Job ID: \" + str(f.train_job_id))\n",
    "    print(\"Run ID: \" + str(f.train_run_id))\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 3: Compare Individual-Level Model Performance\n",
    "After our models have finished running, we'll print out the metrics for each one and compare them. We'll select the best performing model to score our dataset. \n",
    "\n",
    "#### Among the models we tested, the extra trees classifier model ended up having the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in futures: \n",
    "    print(\"\\n************************************\\n\")\n",
    "    if str(f.running()) == \"False\" and f.metadata['run']['status'] != \"exception\":\n",
    "        print(\"MODEL: \" + f.metadata['model']['model'])\n",
    "        print(\"DV: \" + f.metadata['run']['configuration']['data']['y'][0])\n",
    "        print(\"TRAINING TABLE: \" + f.metadata['data_platform']['table_source']['tablename'])\n",
    "        try:\n",
    "            print(\"\\n-----------------------\\n\")\n",
    "            print(\"AUC: \" + str(f.metrics['roc_auc']))\n",
    "            print(\"\\n------------------------\\n\")\n",
    "            print(\"CONFUSION MATRIX:  \" + str(f.metrics['confusion_matrix']))\n",
    "            print(\"\\n------------------------------------\\n\")\n",
    "            print(\"BEST PARAMS:\")\n",
    "            print(f.metadata['model']['cv_best_params'])\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\\n************************************\\n\")\n",
    "    else:\n",
    "        print(\"Model not finished running\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 4: Create Individual-Level Scoring Table and Score\n",
    "We'll create a scoring table with the same features as our training set. This scoring table only has data on females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery\n",
    "\n",
    "DROP VIEW IF EXISTS score_table_uninsured2017;\n",
    "CREATE VIEW score_table_uninsured2017 AS\n",
    "SELECT A.*, B.score AS uninsured_2016\n",
    "FROM\n",
    "(\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM modeling_data\n",
    "    ) AS A\n",
    "    LEFT JOIN\n",
    "    (\n",
    "        SELECT score, join_key2\n",
    "        FROM 2016scores\n",
    "    ) AS B\n",
    "    ON A.id = B.join_key2\n",
    ")\n",
    "WHERE B.score IS NOT NULL\n",
    ";\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Civis API, we'll grab the model with the best performance (sparse logistic), and use this model to score our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Job ID, Run ID, name from output or Civis Platform UI\n",
    "job_id = \"ID NUMBER\"\n",
    "run_id = client.jobs.get(job_id)['last_run']['id']\n",
    "name = client.jobs.get(job_id)['name']\n",
    "\n",
    "# Print Model Info\n",
    "print(\"NAME: \" + name)\n",
    "print(\"JOB ID: \" + str(job_id))\n",
    "print(\"RUN ID: \" + str(run_id))\n",
    "\n",
    "# Load model\n",
    "loaded_model = ModelPipeline.from_existing(job_id, run_id)\n",
    "\n",
    "model_type = loaded_model.model\n",
    "print(model_type)  # model type is sparse logistic\n",
    "\n",
    "# Score table using model\n",
    "scoring = loaded_model.predict(table_name = \"score_table_uninsured2017\", \n",
    "                        database_name = \"database\",\n",
    "                        output_table = \"uninsured2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 5: Aggregate Scores by Geographic Level; Create Aggregate Training & Scoring Tables\n",
    "\n",
    "Now, we'll create a new training table and scoring table, where the features are aggregated by the geographic level of interest (i.e. Census tract). However, for our training table our survey response data will still be used as the dependent variable. \n",
    "\n",
    "We'll also use the scores from our individual-level as a feature in our geographic-level training and scoring tables. We'll take the average scores for each geographic level (i.e. each Census tract), and then we'll append them onto our training and scoring tables. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate features at the Census tract level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery \n",
    "\n",
    "-- Dependent views --\n",
    "DROP VIEW IF EXISTS cdph_train_uninsured_all_agg;\n",
    "DROP VIEW IF EXISTS agg_score_table_uninsured2017;\n",
    "\n",
    "\n",
    "-- Create aggregated table by census tract --\n",
    "DROP VIEW IF EXISTS tract_aggregate_basefile;\n",
    "CREATE VIEW tract_aggregate_basefile AS\n",
    "SELECT\n",
    "  LEFT(census_block, 11) AS census_tract -- ID Census tracts\n",
    "  , AVG(head_hh::float) AS head_hh  \n",
    "  , AVG(hh_count::float) AS hh_count  \n",
    "  , AVG(age::float) AS age  \n",
    "  , AVG(age_18_34::float) AS age_18_34  \n",
    "  , AVG(age_35_49::float) AS age_35_49 \n",
    "  , AVG(age_50_64::float) AS age_50_64 \n",
    "  , AVG(age_65_plus::float) AS age_65_plus \n",
    "  , AVG(hh_avg_age::float) AS hh_avg_age  \n",
    "  , AVG(race_afam::float) AS race_afam\n",
    "  , AVG(race_hispanic::float) AS race_hispanic \n",
    "  , AVG(race_asian::float) AS race_asian \n",
    "  , AVG(race_white::float) AS race_white \n",
    "  , AVG(race_native::float) AS race_native  \n",
    "  , AVG(hh_race_afam::float) AS hh_race_afam  \n",
    "  , AVG(hh_race_hispanic::float) AS hh_race_hispanic  \n",
    "  , AVG(hh_race_asian::float) AS hh_race_asian  \n",
    "  , AVG(hh_race_white::float) AS hh_race_white  \n",
    "  , AVG(hh_race_native::float) AS hh_race_native  \n",
    "  , AVG(hh_all_afam::float) AS hh_all_afam  \n",
    "  , AVG(hh_all_hispanic::float) AS hh_all_hispanic  \n",
    "  , AVG(hh_all_asian::float) AS hh_all_asian  \n",
    "  , AVG(hh_all_white::float) AS hh_all_white  \n",
    "  , AVG(hh_all_native::float) AS hh_all_native  \n",
    "  , AVG(subeth_african_american::float) AS subeth_african_american  \n",
    "  , AVG(subeth_west_indian::float) AS subeth_west_indian  \n",
    "  , AVG(subeth_haitian::float) AS subeth_haitian  \n",
    "  , AVG(subeth_african::float) AS subeth_african  \n",
    "  , AVG(subeth_other_black::float) AS subeth_other_black  \n",
    "  , AVG(subeth_mexican::float) AS subeth_mexican  \n",
    "  , AVG(subeth_cuban::float) AS subeth_cuban  \n",
    "  , AVG(subeth_puerto_rican::float) AS subeth_puerto_rican  \n",
    "  , AVG(subeth_dominican::float) AS subeth_dominican  \n",
    "  , AVG(subeth_other_latin_american::float) AS subeth_other_latin_american  \n",
    "  , AVG(subeth_other_hispanic::float) AS subeth_other_hispanic  \n",
    "  , AVG(subeth_chinese::float) AS subeth_chinese  \n",
    "  , AVG(subeth_indian::float) AS subeth_indian  \n",
    "  , AVG(subeth_filipino::float) AS subeth_filipino  \n",
    "  , AVG(subeth_japanese::float) AS subeth_japanese  \n",
    "  , AVG(subeth_vietnamese::float) AS subeth_vietnamese  \n",
    "  , AVG(subeth_korean::float) AS subeth_korean  \n",
    "  , AVG(subeth_other_asian::float) AS subeth_other_asian  \n",
    "  , AVG(subeth_hmong::float) AS subeth_hmong  \n",
    "  , AVG(spanish::float) AS spanish  \n",
    "  , AVG(gender::float) AS gender  \n",
    "  , AVG(hh_gender::float) AS hh_gender  \n",
    "  , AVG(vb_phone_presence::float) AS vb_phone_presence  \n",
    "  , AVG(vb_phone_listed::float) AS vb_phone_listed  \n",
    "  , AVG(vb_phone_unlisted::float) AS vb_phone_unlisted  \n",
    "  , AVG(vb_email_append_ind::float) AS vb_email_append_ind  \n",
    "  , AVG(vb_email_append_hh::float) AS vb_email_append_hh  \n",
    "  , AVG(vb_deceased::float) AS vb_deceased  \n",
    "  , AVG(elections_pres_2012::float) AS electionses_2012  \n",
    "  , AVG(elections_pres_2008::float) AS electionses_2008  \n",
    "  , AVG(elections_pres_2004::float) AS electionses_2004  \n",
    "  , AVG(elections_gov_recent::float) AS elections_gov_recent  \n",
    "  , AVG(elections_state_avg::float) AS elections_state_avg  \n",
    "  , AVG(elections_fedstate_diff::float) AS elections_fedstate_diff  \n",
    "  , AVG(married::float) AS married  \n",
    "  , AVG(unmarried::float) AS unmarried  \n",
    "  , AVG(children_in_hh::float) AS children_in_hh  \n",
    "  , AVG(num_children_in_hh::float) AS num_children_in_hh  \n",
    "  , AVG(young_children_in_hh::float) AS young_children_in_hh  \n",
    "  , AVG(teenage_children_in_hh::float) AS teenage_children_in_hh  \n",
    "  , AVG(education_highschool::float) AS education_highschool  \n",
    "  , AVG(education_collegegrad::float) AS education_collegegrad  \n",
    "  , AVG(num_in_hh::float) AS num_in_hh  \n",
    "  , AVG(religion_jewish::float) AS religion_jewish  \n",
    "  , AVG(religion_mormon::float) AS religion_mormon  \n",
    "  , AVG(religion_muslim::float) AS religion_muslim  \n",
    "  , AVG(religion_catholic::float) AS religion_catholic  \n",
    "  , AVG(religion_evangelicalotestant::float) AS religion_evangelicalotestant  \n",
    "  , AVG(religion_mainlineotestant::float) AS religion_mainlineotestant  \n",
    "  , AVG(religion_orthodox_christian::float) AS religion_orthodox_christian  \n",
    "  , AVG(religion_jehovah_witness::float) AS religion_jehovah_witness  \n",
    "  , AVG(religion_hindu::float) AS religion_hindu  \n",
    "  , AVG(religion_buddhist::float) AS religion_buddhist  \n",
    "  , AVG(vehicleowner::float) AS vehicleowner  \n",
    "  , AVG(homeowner::float) AS homeowner  \n",
    "  , AVG(property_type_singlefamily::float) AS property_type_singlefamily  \n",
    "  , AVG(property_type_multifamily::float) AS property_type_multifamily  \n",
    "  , AVG(address_type_firm::float) AS address_type_firm  \n",
    "  , AVG(address_type_general_delivery::float) AS address_type_general_delivery  \n",
    "  , AVG(address_type_high_rise::float) AS address_type_high_rise  \n",
    "  , AVG(address_type_po_box::float) AS address_type_po_box  \n",
    "  , AVG(address_type_rural::float) AS address_type_rural  \n",
    "  , AVG(address_type_street::float) AS address_type_street  \n",
    "  , AVG(has_ncoa_return_code::float) AS has_ncoa_return_code  \n",
    "  , AVG(length_of_residence::float) AS length_of_residence  \n",
    "  , AVG(length_of_residence_is_null::float) AS length_of_residence_is_null  \n",
    "  , AVG(home_sqft::float) AS home_sqft  \n",
    "  , AVG(home_sqft_is_null::float) AS home_sqft_is_null  \n",
    "  , AVG(home_total_value::float) AS home_total_value  \n",
    "  , AVG(home_total_value_is_unknown::float) AS home_total_value_is_unknown  \n",
    "  , AVG(log_home_value_bucket::float) AS log_home_value_bucket  \n",
    "  , AVG(home_value_is_null::float) AS home_value_is_null  \n",
    "  , AVG(home_purchase_year::float) AS home_purchase_year  \n",
    "  , AVG(home_purchase_year_is_null::float) AS home_purchase_year_is_null  \n",
    "  , AVG(log_household_net_worth_bucket::float) AS log_household_net_worth_bucket  \n",
    "  , AVG(household_net_worth_is_null::float) AS household_net_worth_is_null  \n",
    "  , AVG(head_hh_salary_amt::float) AS head_hh_salary_amt  \n",
    "  , AVG(head_hh_salary_amt_is_null::float) AS head_hh_salary_amt_is_null  \n",
    "  , AVG(log_household_income_bucket::float) AS log_household_income_bucket  \n",
    "  , AVG(household_income_is_null::float) AS household_income_is_null  \n",
    "  , AVG(donor_charity::float) AS donor_charity  \n",
    "  , AVG(donor_enviro_causes::float) AS donor_enviro_causes  \n",
    "  , AVG(hh_donor_charity_pctile::float) AS hh_donor_charity_pctile  \n",
    "  , AVG(hh_donor_charity::float) AS hh_donor_charity  \n",
    "  , AVG(hh_donor_enviro_causes::float) AS hh_donor_enviro_causes  \n",
    "  , AVG(dog_enthusiast::float) AS dog_enthusiast  \n",
    "  , AVG(cat_enthusiast::float) AS cat_enthusiast  \n",
    "  , AVG(pet_enthusiast::float) AS pet_enthusiast  \n",
    "  , AVG(travel_domestic_foreign::float) AS travel_domestic_foreign  \n",
    "  , AVG(license_hunt_fish::float) AS license_hunt_fish  \n",
    "  , AVG(religious_purchase::float) AS religious_purchase  \n",
    "  , AVG(political_purchase::float) AS political_purchase  \n",
    "  , AVG(health_institution_purchase::float) AS health_institution_purchase  \n",
    "  , AVG(general_purchase::float) AS general_purchase  \n",
    "  , AVG(hh_license_hunt_fish::float) AS hh_license_hunt_fish  \n",
    "  , AVG(hh_religious_purchase::float) AS hh_religious_purchase  \n",
    "  , AVG(hh_political_purchase::float) AS hh_political_purchase  \n",
    "  , AVG(hh_health_institution_purchase::float) AS hh_health_institution_purchase  \n",
    "  , AVG(hh_general_purchase::float) AS hh_general_purchase  \n",
    "  , AVG(presence_of_cell_phone::float) AS presence_of_cell_phone  \n",
    "  , AVG(presence_of_cell_phone_modeled::float) AS presence_of_cell_phone_modeled  \n",
    "  , AVG(hh_has_credit_card::float) AS hh_has_credit_card  \n",
    "  , AVG(online_is_online::float) AS online_is_online  \n",
    "  , AVG(online_facebook::float) AS online_facebook  \n",
    "  , AVG(online_purchaser::float) AS online_purchaser  \n",
    "  , AVG(hh_online_social_network_twentile::float) AS hh_online_social_network_twentile  \n",
    "  , AVG(hh_online_is_online::float) AS hh_online_is_online  \n",
    "  , AVG(hh_online_facebook::float) AS hh_online_facebook  \n",
    "  , AVG(employed::float) AS employed  \n",
    "  , AVG(employed_unknown::float) AS employed_unknown  \n",
    "  , AVG(retired::float) AS retired  \n",
    "  , AVG(hh_business_owner::float) AS hh_business_owner  \n",
    "  , AVG(emp_nurse::float) AS emp_nurse  \n",
    "  , AVG(emp_beauty::float) AS emp_beauty  \n",
    "  , AVG(emp_self_employed::float) AS emp_self_employed  \n",
    "  , AVG(emp_healthcare::float) AS emp_healthcare  \n",
    "  , AVG(emp_nursingovider::float) AS emp_nursingovider  \n",
    "  , AVG(emp_dentalovider::float) AS emp_dentalovider  \n",
    "  , AVG(emp_healthcareovider::float) AS emp_healthcareovider  \n",
    "  , AVG(emp_realestate::float) AS emp_realestate  \n",
    "  , AVG(emp_educator::float) AS emp_educator  \n",
    "  , AVG(emp_pilot::float) AS emp_pilot  \n",
    "  , AVG(emp_aviation_industry::float) AS emp_aviation_industry  \n",
    "  , AVG(emp_postal::float) AS emp_postal  \n",
    "  , AVG(emp_federal::float) AS emp_federal  \n",
    "  , AVG(emp_military::float) AS emp_military  \n",
    "  , AVG(hh_emp_active_military::float) AS hh_emp_active_military  \n",
    "  , AVG(hh_emp_active_military_modeled::float) AS hh_emp_active_military_modeled  \n",
    "  , AVG(hh_emp_inactive_military::float) AS hh_emp_inactive_military  \n",
    "  , AVG(hh_emp_inactive_military_modeled::float) AS hh_emp_inactive_military_modeled  \n",
    "  , AVG(hh_employed::float) AS hh_employed  \n",
    "  , AVG(hh_retired::float) AS hh_retired  \n",
    "  , AVG(hh_emp_nurse::float) AS hh_emp_nurse  \n",
    "  , AVG(hh_emp_beauty::float) AS hh_emp_beauty  \n",
    "  , AVG(hh_emp_healthcare::float) AS hh_emp_healthcare  \n",
    "  , AVG(hh_emp_realestate::float) AS hh_emp_realestate  \n",
    "  , AVG(hh_emp_educator::float) AS hh_emp_educator  \n",
    "  , AVG(zip5_pct_catholic::float) AS zip5_pct_catholic  \n",
    "  , AVG(zip5_pct_jewish::float) AS zip5_pct_jewish  \n",
    "  , AVG(zip5_pct_dems_per_reg::float) AS zip5_pct_dems_per_reg  \n",
    "  , AVG(zip5_pct_registered::float) AS zip5_pct_registered  \n",
    "  , AVG(zip5_pct_feccontributions_dem_2way::float) AS zip5_pct_feccontributions_dem_2way  \n",
    "  , AVG(urban::float) AS urban  \n",
    "  , AVG(suburban::float) AS suburban  \n",
    "  , AVG(rural::float) AS rural  \n",
    "  , AVG(county_is_in_msa::float) AS county_is_in_msa  \n",
    "  , AVG(is_in_place::float) AS is_in_place  \n",
    "  , AVG(place_is_in_principal_city::float) AS place_is_in_principal_city  \n",
    "  , AVG(pct_under18::float) AS pct_under18  \n",
    "  , AVG(pct_18plus::float) AS pct_18plus  \n",
    "  , AVG(pct_race5way_hispanic::float) AS pct_race5way_hispanic  \n",
    "  , AVG(pct_race5way_black::float) AS pct_race5way_black  \n",
    "  , AVG(pct_race5way_asian::float) AS pct_race5way_asian  \n",
    "  , AVG(pct_race5way_native::float) AS pct_race5way_native  \n",
    "  , AVG(total_hh::float) AS total_hh  \n",
    "  , AVG(pct_hh_owned_with_loan::float) AS pct_hh_owned_with_loan  \n",
    "  , AVG(pct_hh_owned_no_loan::float) AS pct_hh_owned_no_loan  \n",
    "  , AVG(pct_hh_renter::float) AS pct_hh_renter  \n",
    "  , AVG(pct_hh_single_family_head::float) AS pct_hh_single_family_head  \n",
    "  , AVG(pct_hh_with_own_children_under18::float) AS pct_hh_with_own_children_under18  \n",
    "  , AVG(pct_hh_1_person::float) AS pct_hh_1_person  \n",
    "  , AVG(pct_hh_husband_wife_family::float) AS pct_hh_husband_wife_family  \n",
    "  , AVG(pums11model_fpl_under138::float) AS pums11model_fpl_under138  \n",
    "  , AVG(pums11model_fpl_139to400::float) AS pums11model_fpl_139to400  \n",
    "  , AVG(civismodel_incomeunder40k::float) AS civismodel_incomeunder40k  \n",
    "  , AVG(civismodel_incomeover80k::float) AS civismodel_incomeover80k  \n",
    "  , AVG(total_pop::float) AS total_pop  \n",
    "  , AVG(log_pop_density::float) AS log_pop_density  \n",
    "  , AVG(log_total_hispanic_density::float) AS log_total_hispanic_density  \n",
    "  , AVG(log_total_white_density::float) AS log_total_white_density  \n",
    "  , AVG(log_total_black_density::float) AS log_total_black_density  \n",
    "  , AVG(log_total_native_american_density::float) AS log_total_native_american_density  \n",
    "  , AVG(log_total_asian_density::float) AS log_total_asian_density  \n",
    "  , AVG(total_hawaiian_pac_islander_pct::float) AS total_hawaiian_pac_islander_pct  \n",
    "  , AVG(log_total_other_race_density::float) AS log_total_other_race_density  \n",
    "  , AVG(total_multi_race_pct::float) AS total_multi_race_pct  \n",
    "  , AVG(log_total_multi_race_density::float) AS log_total_multi_race_density  \n",
    "  , AVG(adult_pct::float) AS adult_pct  \n",
    "  , AVG(adult_hispanic_pct::float) AS adult_hispanic_pct  \n",
    "  , AVG(log_adult_hispanic_density::float) AS log_adult_hispanic_density  \n",
    "  , AVG(adult_white_pct::float) AS adult_white_pct  \n",
    "  , AVG(log_adult_white_density::float) AS log_adult_white_density  \n",
    "  , AVG(adult_black_pct::float) AS adult_black_pct  \n",
    "  , AVG(log_adult_black_density::float) AS log_adult_black_density  \n",
    "  , AVG(adult_native_american_pct::float) AS adult_native_american_pct  \n",
    "  , AVG(log_adult_native_american_density::float) AS log_adult_native_american_density  \n",
    "  , AVG(adult_asian_pct::float) AS adult_asian_pct  \n",
    "  , AVG(log_adult_asian_density::float) AS log_adult_asian_density  \n",
    "  , AVG(adult_hawaiian_pac_islander_pct::float) AS adult_hawaiian_pac_islander_pct  \n",
    "  , AVG(adult_other_race_pct::float) AS adult_other_race_pct  \n",
    "  , AVG(log_adult_other_race_density::float) AS log_adult_other_race_density  \n",
    "  , AVG(adult_multi_race_pct::float) AS adult_multi_race_pct  \n",
    "  , AVG(log_adult_multi_race_density::float) AS log_adult_multi_race_density  \n",
    "  , AVG(minor_pct::float) AS minor_pct  \n",
    "  , AVG(minor_hispanic_pct::float) AS minor_hispanic_pct  \n",
    "  , AVG(log_minor_hispanic_density::float) AS log_minor_hispanic_density  \n",
    "  , AVG(minor_white_pct::float) AS minor_white_pct  \n",
    "  , AVG(log_minor_white_density::float) AS log_minor_white_density  \n",
    "  , AVG(minor_black_pct::float) AS minor_black_pct  \n",
    "  , AVG(log_minor_black_density::float) AS log_minor_black_density  \n",
    "  , AVG(minor_native_american_pct::float) AS minor_native_american_pct  \n",
    "  , AVG(minor_asian_pct::float) AS minor_asian_pct  \n",
    "  , AVG(log_minor_multi_race_density::float) AS log_minor_multi_race_density  \n",
    "  , AVG(median_age::float) AS median_age  \n",
    "  , AVG(median_age_male::float) AS median_age_male  \n",
    "  , AVG(median_age_female::float) AS median_age_female  \n",
    "  , AVG(univacant_density::float) AS univacant_density  \n",
    "  , AVG(univacant_rented_pct::float) AS univacant_rented_pct  \n",
    "  , AVG(univacant_for_sale_pct::float) AS univacant_for_sale_pct  \n",
    "  , AVG(univacant_sold_pct::float) AS univacant_sold_pct  \n",
    "  , AVG(univacant_seasonal_etc_use_pct::float) AS univacant_seasonal_etc_use_pct  \n",
    "  , AVG(univacant_migrant_workers_pct::float) AS univacant_migrant_workers_pct  \n",
    "  , AVG(univacant_other_pct::float) AS univacant_other_pct  \n",
    "  , AVG(pct_employment_construction::float) AS pct_employment_construction  \n",
    "  , AVG(pct_employment_manufacturing::float) AS pct_employment_manufacturing  \n",
    "  , AVG(pct_employment_wholesale::float) AS pct_employment_wholesale  \n",
    "  , AVG(pct_employment_retail::float) AS pct_employment_retail  \n",
    "  , AVG(pct_employment_finance::float) AS pct_employment_finance  \n",
    "  , AVG(pct_employment_management::float) AS pct_employment_management  \n",
    "  , AVG(pct_employment_educational::float) AS pct_employment_educational  \n",
    "  , AVG(pct_employment_health::float) AS pct_employment_health  \n",
    "  , AVG(pct_employment_arts::float) AS pct_employment_arts  \n",
    "  , AVG(indian_reservation::float) AS indian_reservation  \n",
    "  , AVG(military_base::float) AS military_base  \n",
    "  , AVG(pct_pop_corrections_facility::float) AS pct_pop_corrections_facility  \n",
    "  , AVG(pct_pop_nursing_facility::float) AS pct_pop_nursing_facility  \n",
    "  , AVG(pct_pop_military_quarters::float) AS pct_pop_military_quarters  \n",
    "  , AVG(pct_pop_student_housing::float) AS pct_pop_student_housing  \n",
    "  , AVG(pct_pop_evangelical::float) AS pct_pop_evangelical  \n",
    "  , AVG(pct_pop_catholic::float) AS pct_pop_catholic  \n",
    "  , AVG(pct_pop_blackotestant::float) AS pct_pop_blackotestant  \n",
    "  , AVG(pct_pop_muslim::float) AS pct_pop_muslim  \n",
    "  , AVG(pct_pop_mormon::float) AS pct_pop_mormon  \n",
    "  , AVG(pct_pop_jewish::float) AS pct_pop_jewish  \n",
    "  , AVG(pct_pop_buddhist::float) AS pct_pop_buddhist  \n",
    "  , AVG(pct_pop_hindu::float) AS pct_pop_hindu  \n",
    "  , AVG(median_age_white_male::float) AS median_age_white_male  \n",
    "  , AVG(pct_white_male_less_high_school::float) AS pct_white_male_less_high_school  \n",
    "  , AVG(pct_white_female_less_high_school::float) AS pct_white_female_less_high_school  \n",
    "  , AVG(median_hh_income::float) AS median_hh_income  \n",
    "  , AVG(pct_noncitizen::float) AS pct_noncitizen  \n",
    "  , AVG(pct_moved_past_year_within_county::float) AS pct_moved_past_year_within_county  \n",
    "  , AVG(pct_moved_past_year_all::float) AS pct_moved_past_year_all  \n",
    "  , AVG(pct_leave_for_work_4pmto5am::float) AS pct_leave_for_work_4pmto5am  \n",
    "  , AVG(pct_commute_over90min::float) AS pct_commute_over90min  \n",
    "  , AVG(pct_vehicle_available::float) AS pct_vehicle_available  \n",
    "  , AVG(pct_enrolled_in_higher_ed::float) AS pct_enrolled_in_higher_ed  \n",
    "  , AVG(pct_educ_no_hs::float) AS pct_educ_no_hs  \n",
    "  , AVG(pct_educ_bachelors::float) AS pct_educ_bachelors  \n",
    "  , AVG(pct_in_labor_force::float) AS pct_in_labor_force  \n",
    "  , AVG(pct_disabled::float) AS pct_disabled  \n",
    "  , AVG(outflow_same_state::float) AS outflow_same_state  \n",
    "  , AVG(outflow_foreign::float) AS outflow_foreign  \n",
    "  , AVG(outflow_total::float) AS outflow_total  \n",
    "  , AVG(inflow_same_state::float) AS inflow_same_state  \n",
    "  , AVG(inflow_diff_state::float) AS inflow_diff_state  \n",
    "  , AVG(inflow_foreign::float) AS inflow_foreign  \n",
    "  , AVG(inflow_total::float) AS inflow_total  \n",
    "  , AVG(exemptions_per_return::float) AS exemptions_per_return  \n",
    "  , AVG(dependenper_return::float) AS dependenper_return  \n",
    "  , AVG(pct_single_returns::float) AS pct_single_returns  \n",
    "  , AVG(pct_joint_returns::float) AS pct_joint_returns  \n",
    "  , AVG(pct_headofhousehold_returns::float) AS pct_headofhousehold_returns  \n",
    "  , AVG(avg_adjusted_gross_income::float) AS avg_adjusted_gross_income  \n",
    "  , AVG(pct_farm_returns::float) AS pct_farm_returns  \n",
    "  , AVG(pct_retiree_returns::float) AS pct_retiree_returns  \n",
    "  , AVG(pct_salarywages_returns::float) AS pct_salarywages_returns  \n",
    "  , AVG(avg_amnt_salarywages::float) AS avg_amnt_salarywages  \n",
    "  , AVG(pct_businessincome_returns::float) AS pct_businessincome_returns  \n",
    "  , AVG(avg_amnt_businessincome::float) AS avg_amnt_businessincome  \n",
    "  , AVG(avg_amnt_unemployed_benefits::float) AS avg_amnt_unemployed_benefits  \n",
    "  , AVG(pct_socsecurity_returns::float) AS pct_socsecurity_returns  \n",
    "  , AVG(avg_amnt_socsecurity_benefits::float) AS avg_amnt_socsecurity_benefits  \n",
    "  , AVG(avg_amnt_contributions::float) AS avg_amnt_contributions  \n",
    "  , AVG(pct_energy_taxcredit_returns::float) AS pct_energy_taxcredit_returns  \n",
    "  , AVG(avg_amnt_energy_taxcredit_per_return::float) AS avg_amnt_energy_taxcredit_per_return  \n",
    "  , AVG(avg_amnt_child_taxcredit_per_return::float) AS avg_amnt_child_taxcredit_per_return  \n",
    "  , AVG(pct_eitc_returns::float) AS pct_eitc_returns  \n",
    "  , AVG(avg_amnt_eitc_per_return::float) AS avg_amnt_eitc_per_return  \n",
    "  , AVG(veteran_pct::float) AS veteran_pct  \n",
    "  , AVG(employ_current_rate::float) AS employ_current_rate  \n",
    "  , AVG(employ_ten_month_low::float) AS employ_ten_month_low  \n",
    "  , AVG(retired_workers::float) AS retired_workers  \n",
    "  , AVG(disabled_workers::float) AS disabled_workers  \n",
    "  , AVG(widowers::float) AS widowers  \n",
    "  , AVG(children::float) AS children  \n",
    "  , AVG(retired_workers_benefits::float) AS retired_workers_benefits  \n",
    "  , AVG(widower_benefits::float) AS widower_benefits  \n",
    "  , AVG(total_crimes::float) AS total_crimes  \n",
    "  , AVG(rape::float) AS rape  \n",
    "  , AVG(agg_assault::float) AS agg_assault  \n",
    "  , AVG(prostitution::float) AS prostitution  \n",
    "  , AVG(sex_offense::float) AS sex_offense  \n",
    "  , AVG(vehicle_theft::float) AS vehicle_theft  \n",
    "  , AVG(disorderly_conduct::float) AS disorderly_conduct  \n",
    "  , AVG(drug_total::float) AS drug_total  \n",
    "  , AVG(median_home_list_price::float) AS median_home_list_price  \n",
    "  , AVG(median_rental_price::float) AS median_rental_price  \n",
    "  , AVG(median_listing_price_sqfoot::float) AS median_listing_price_sqfoot  \n",
    "  , AVG(pct_homes_price_reduction::float) AS pct_homes_price_reduction  \n",
    "  , AVG(median_price_reduction::float) AS median_price_reduction  \n",
    "  , AVG(log_distance_to_starbucks::float) AS log_distance_to_starbucks  \n",
    "  , AVG(log_distance_to_elementary_school::float) AS log_distance_to_elementary_school  \n",
    "  , AVG(log_distance_to_high_school::float) AS log_distance_to_high_school  \n",
    "  , AVG(log_distance_to_homeless_shelter::float) AS log_distance_to_homeless_shelter  \n",
    "  , AVG(log_distance_to_hospital::float) AS log_distance_to_hospital  \n",
    "  , AVG(log_distance_to_assisted_living::float) AS log_distance_to_assisted_living  \n",
    "  , AVG(log_distance_to_independent_living::float) AS log_distance_to_independent_living  \n",
    "  , AVG(log_distance_to_kindergarten::float) AS log_distance_to_kindergarten  \n",
    "  , AVG(log_distance_to_middle_school::float) AS log_distance_to_middle_school  \n",
    "  , AVG(log_distance_to_nursing_home::float) AS log_distance_to_nursing_home  \n",
    "  , AVG(log_distance_to_synagogue::float) AS log_distance_to_synagogue  \n",
    "  , AVG(log_distance_to_university::float) AS log_distance_to_university  \n",
    "  , AVG(housing_temp_address::float) AS housing_temp_address  \n",
    "  , AVG(amenities99_amenity_rank::float) AS amenities99_amenity_rank  \n",
    "  , AVG(fast_food_restaurants::float) AS fast_food_restaurants  \n",
    "  , AVG(full_service_restaurants::float) AS full_service_restaurants  \n",
    "  , AVG(grocery_stores_per_cap::float) AS grocery_stores_per_cap  \n",
    "  , AVG(rec_facilities::float) AS rec_facilities  \n",
    "  , AVG(snap_benefiper_cap::float) AS snap_benefiper_cap  \n",
    "  , AVG(wic_redemptions_per_cap::float) AS wic_redemptions_per_cap  \n",
    "  , AVG(sfree_lunch_eligible_pct::float) AS sfree_lunch_eligible_pct  \n",
    "  , AVG(sreduced_lunch_eligible_pct::float) AS sreduced_lunch_eligible_pct  \n",
    "  , AVG(low_access_to_store_pct::float) AS low_access_to_store_pct  \n",
    "  , AVG(no_car_low_access_to_store_pct::float) AS no_car_low_access_to_store_pct  \n",
    "  , AVG(mail_return_pct::float) AS mail_return_pct  \n",
    "  , AVG(parent::float) AS parent  \n",
    "  , AVG(uninsured_2015::float) AS uninsured_2015  \n",
    "  , AVG(marriage::float) AS marriage \n",
    "  , AVG(uninsured_2016) AS uninsured_2016\n",
    "  FROM score_table_uninsured2017  -- use individual-level scoring table for model trained on individual-level data\n",
    "  WHERE census_block IS NOT NULL\n",
    "  GROUP BY 1   -- group by Census tracts\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate individual-level model scores at the Census tract level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery \n",
    "\n",
    "DROP VIEW IF EXISTS cdph_train_uninsured_all_agg;\n",
    "DROP VIEW IF EXISTS agg_score_table_uninsured2017;\n",
    "DROP VIEW IF EXISTS agg_uninsured2017_scores;\n",
    "CREATE VIEW agg_uninsured2017_scores AS\n",
    "SELECT \n",
    "LEFT(modeling.census_block, 11) AS census_tract\n",
    ", AVG(scores.cdph_uninsured) AS uninsured2017_scores\n",
    "FROM uninsured2017 AS scores\n",
    "LEFT JOIN modeling_data AS modeling\n",
    "ON modeling.id = scores.id\n",
    "GROUP BY 1\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new scoring table with data aggregated at the census tract level; aggregated individual-level scores appended on as a column.\n",
    "Each row is a geographic level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery \n",
    "\n",
    "DROP VIEW IF EXISTS cdph_train_uninsured_all_agg;\n",
    "DROP VIEW IF EXISTS agg_score_table_uninsured2017;\n",
    "CREATE VIEW agg_score_table_uninsured2017 AS\n",
    "SELECT \n",
    "bridge.ca,\n",
    "agg_basefile.*,\n",
    "agg_scores.uninsured2017_scores\n",
    "FROM tract_aggregate_basefile AS agg_basefile\n",
    "LEFT JOIN\n",
    "agg_uninsured2017_scores AS agg_scores\n",
    "ON agg_basefile.census_tract = agg_scores.census_tract\n",
    "LEFT JOIN\n",
    "ca_tract_bridge AS bridge   -- this is a table connect Census tracts to Chicago community areas\n",
    "ON bridge.id = agg_basefile.census_tract\n",
    "WHERE bridge.id IS NOT NULL  -- subsetting scoring table to only include Chicago Census tracts\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new training table with aggregated data; this is at the individual level but the features are aggregated by Census tract; aggregated individual-level scores are appended on as a column\n",
    "\n",
    "Each row is an individual, but the features/columns are aggregated by geographic level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%civisquery\n",
    "\n",
    "DROP VIEW IF EXISTS scratch.cdph_train_uninsured_all_agg;\n",
    "CREATE VIEW scratch.cdph_train_uninsured_all_agg AS\n",
    "SELECT \n",
    "A.id,\n",
    "A.cdph_uninsured,\n",
    "A.weight,\n",
    "B.*\n",
    "FROM\n",
    "(\n",
    "    SELECT \n",
    "    train.id,\n",
    "    train.cdph_uninsured,\n",
    "    train.weight,\n",
    "    LEFT(modeling.census_block, 11) AS census_tract\n",
    "    FROM cdph_train_uninsured_all_female AS train\n",
    "    LEFT JOIN modeling_data AS modeling\n",
    "    ON train.id = modeling.id\n",
    ") AS A\n",
    "LEFT JOIN\n",
    "(\n",
    "    SELECT \n",
    "    agg_basefile.*, \n",
    "    agg_scores.uninsured2017_scores\n",
    "    FROM tract_aggregate_basefile AS agg_basefile\n",
    "    LEFT JOIN\n",
    "    agg_uninsured2017_scores AS agg_scores\n",
    "    ON agg_basefile.census_tract = agg_scores.census_tract\n",
    ") AS B\n",
    "ON A.census_tract = B.census_tract\n",
    "WHERE A.cdph_uninsured IS NOT NULL\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 6: Train Geographic-Level Model\n",
    "Set up modeling pipeline by specifying which models to train, and selecting the parameters for the different training tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_models = {\n",
    "    'sparse_logistic': {},\n",
    "    'extra_trees_classifier': 'hyperband',\n",
    "    'gradient_boosting_classifier': 'hyperband',\n",
    "    'random_forest_classifier': 'hyperband'\n",
    "} \n",
    "\n",
    "\n",
    "agg_futures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, params in agg_models.items():\n",
    "\n",
    "    print(\"Currently testing model: \" + i)\n",
    "    print(\"Params: \" + str(params))\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "    m = ModelPipeline(model = i, \n",
    "                      model_name = 'AGG DATA, WEIGHTED -- ' + i + ' DV is cdph_uninsured',\n",
    "                      dependent_variable = 'cdph_uninsured',\n",
    "                      primary_key = 'id',\n",
    "                      excluded_columns = ['census_tract'\n",
    "                                         ],\n",
    "                      cross_validation_parameters = params,\n",
    "                      memory_requested = 5000,\n",
    "                      cpu_requested = 1024)\n",
    "\n",
    "    train = m.train(table_name = 'cdph_train_uninsured_all_agg',\n",
    "                    fit_params = {'sample_weight': 'weight'},\n",
    "                    database_name = 'database'\n",
    "                    )\n",
    "    agg_futures.append(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that jobs are running in the Civis platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in agg_futures:\n",
    "    print(\"Model running?  \" + str(f.running()))\n",
    "    print(\"Job ID: \" + str(f.job_id))\n",
    "    print(\"Train Job ID: \" + str(f.train_job_id))\n",
    "    print(\"Run ID: \" + str(f.train_run_id))\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 7: Compare Geographic-level Model Performance\n",
    "\n",
    "After our models have finished running, we'll print out the metrics for each one and compare them. We'll select the best performing model to score our dataset.\n",
    "\n",
    "#### Among the models we tested, the sparse logistic model ended up having the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in agg_futures: \n",
    "    print(\"\\n************************************\\n\")\n",
    "    if str(f.running()) == \"False\" and f.metadata['run']['status'] != \"exception\":\n",
    "        print(\"MODEL: \" + f.metadata['model']['model'])\n",
    "        print(\"DV: \" + f.metadata['run']['configuration']['data']['y'][0])\n",
    "        print(\"TRAINING TABLE: \" + f.metadata['data_platform']['table_source']['tablename'])\n",
    "        print(\"Job ID: \" + str(f.job_id))\n",
    "        try:\n",
    "            print(\"\\n-----------------------\\n\")\n",
    "            print(\"AUC: \" + str(f.metrics['roc_auc']))\n",
    "            print(\"\\n------------------------\\n\")\n",
    "            print(\"CONFUSION MATRIX:  \" + str(f.metrics['confusion_matrix']))\n",
    "            print(\"\\n------------------------------------\\n\")\n",
    "            print(\"BEST PARAMS:\")\n",
    "            print(f.metadata['model']['cv_best_params'])\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\\n************************************\\n\")\n",
    "    else:\n",
    "        print(\"Model not finished running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "\n",
    "# STEP 8: Score Geographic-Level Scoring Table\n",
    "\n",
    "### Load model trained on aggregated data for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"ID NUMBER\"\n",
    "\n",
    "\n",
    "run_id = client.jobs.get(job_id)['last_run']['id']\n",
    "name = client.jobs.get(job_id)['name']\n",
    "\n",
    "# Print Model Info\n",
    "print(\"NAME: \" + name)\n",
    "print(\"JOB ID: \" + str(job_id))\n",
    "print(\"RUN ID: \" + str(run_id))\n",
    "\n",
    "# Load model\n",
    "loaded_agg_model = ModelPipeline.from_existing(job_id, run_id)\n",
    "\n",
    "model_type = loaded_agg_model.model\n",
    "print(model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score scoring table with aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score table using model\n",
    "scoring = loaded_agg_model.predict(table_name = \"agg_score_table_uninsured2017\", \n",
    "                               database_name = \"database\",\n",
    "                               output_table = \"uninsured2017_aggscores\",\n",
    "                               if_exists = \"drop\",\n",
    "                               primary_key = \"census_tract\"\n",
    "                              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
